{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('last/all.jsonl', orient='records', lines=True)\n",
    "copy = pd.read_json('last/all.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_json('last/all.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"dbmdz/bert-base-turkish-128k-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path, max_len=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeDegreeLabels(data):\n",
    "    for item in range(len(data.label)):\n",
    "        for lbl in data.iloc[item].label:\n",
    "            if(lbl[2] == \"Derece 1\" or lbl[2] == \"Derece 2\" or lbl[2] == \"Derece 3\"): \n",
    "                data.iloc[item].label.remove(lbl)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = removeDegreeLabels(copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenizedLabels(data):\n",
    "    labels_list = []\n",
    "    for text, doccano_label_list in zip(data['text'], data['label']):\n",
    "        encoding = tokenizer(text, return_offsets_mapping=True)\n",
    "        labels = [None] * len(encoding[\"offset_mapping\"])\n",
    "        doccano_label_index = 0\n",
    "        for index, token_tupple in enumerate(encoding[\"offset_mapping\"]):\n",
    "            doccano_label = doccano_label_list[doccano_label_index]\n",
    "            if(token_tupple == (0,0)): continue\n",
    "\n",
    "            if(token_tupple[0] > doccano_label[1] and ((doccano_label_index+1) != len(doccano_label_list))):\n",
    "                doccano_label_index += 1\n",
    "                doccano_label = doccano_label_list[doccano_label_index]\n",
    "\n",
    "            if(doccano_label[0] <= token_tupple[0] <= doccano_label[1]):\n",
    "                labels[index] = doccano_label[2]\n",
    "            else:\n",
    "                labels[index] = 'O'\n",
    "        labels_list.append(labels)\n",
    "    return pd.Series(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumLabels(labels):\n",
    "    label2id = {None:-100, 'O':0, 'Destek':1, 'Direnç':2, 'Hedef':3, 'Pozitif Yorum':4, 'Negatif Yorum':5, 'Vade':6}\n",
    "    id2label = {v:k for k,v in label2id.items()}\n",
    "    bert_labels_id = bert_labels.map(lambda x: [label2id[y] for y in x])\n",
    "    return bert_labels_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_labels = getTokenizedLabels(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_labels_id = enumLabels(bert_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['tokens'] = new.text.apply(lambda x: tokenizer(x).tokens())\n",
    "new['input_ids'] = new.text.apply(lambda x: tokenizer(x).input_ids)\n",
    "new['attention_mask'] = new.text.apply(lambda x: tokenizer(x).attention_mask)\n",
    "new['token_type_ids'] = new.text.apply(lambda x: tokenizer(x).token_type_ids)\n",
    "new['bert_labels']= bert_labels\n",
    "new['bert_label_ids'] = bert_labels_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = new.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.drop(['id', 'label', 'text', 'date', 'user', 'rt', 'fav', 'followers', 'verified', 'tokens', 'bert_labels'], axis=1, inplace=True)\n",
    "new.rename(columns={'bert_label_ids':'labels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(new, test_size=0.1, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.11, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(909, 113, 114)"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.Dataset.from_pandas(train)\n",
    "test_dataset = datasets.Dataset.from_pandas(test)\n",
    "val_dataset = datasets.Dataset.from_pandas(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'token_type_ids', 'labels'],\n",
       "    num_rows: 909\n",
       "})"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-100,    0,    0,    0,    1,    0,    2,    2,    2,    2,    0,    0,\n",
       "            0,    0,    0,    0,    1,    1,    1,    0,    2,    2,    2,    0,\n",
       "            0,    0,    0,    1,    1,    1,    0,    2,    2,    2,    0,    0,\n",
       "            0,    1,    1,    0,    2,    2,    2,    0,    0,    0,    0,    0,\n",
       "            1,    1,    1,    0,    2,    2,    2,    0,    0,    0,    0,    0,\n",
       "            0,    0,    1,    1,    1,    0,    2,    2,    2,    0,    0,    0,\n",
       "            0,    0,    1,    1,    1,    0,    2,    2,    2,    0,    0,    0,\n",
       "            0,    0,    0,    0,    1,    0,    2,    0,    0,    0, -100],\n",
       "        [-100,    0,    0,    0,    2,    2,    2,    0,    0,    4,    4,    0,\n",
       "            0, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "         -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]])"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([train_dataset[i] for i in range(2)])\n",
    "batch[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'Destek',\n",
       " 'Destek',\n",
       " 'Destek',\n",
       " 'O',\n",
       " 'O',\n",
       " 'Direnç',\n",
       " 'Direnç',\n",
       " 'Direnç']"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = data['bert_labels'][0][1:-1]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Destek seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Direnç seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'estek': {'precision': 0.5,\n",
       "  'recall': 1.0,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 1},\n",
       " 'irenç': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 0.6666666666666666,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 0.8,\n",
       " 'overall_accuracy': 0.9230769230769231}"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = labels.copy()\n",
    "preds[2] = \"Destek\"\n",
    "metric.compute(predictions=[preds], references=[labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"O\", \"Destek\", \"Direnç\", \"Hedef\", \"Pozitif Yorum\", \"Negatif Yorum\", \"Vade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {'O':0, 'Destek':1, 'Direnç':2, 'Hedef':3, 'Pozitif Yorum':4, 'Negatif Yorum':5, 'Vade':6}\n",
    "id2label = {v:k for k,v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/dbmdz/bert-base-turkish-128k-uncased/resolve/main/config.json from cache at /Users/damlakonur/.cache/huggingface/transformers/120e27321f5f101e4616b430bb300523eb0c464006badb271fc4a80ecb3f4551.453a629e781b4c858049daeb69936fc02d2ee7e3314c6c65fa5f432c13470419\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"dbmdz/bert-base-turkish-128k-uncased\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"Destek\",\n",
      "    \"2\": \"Diren\\u00e7\",\n",
      "    \"3\": \"Hedef\",\n",
      "    \"4\": \"Pozitif Yorum\",\n",
      "    \"5\": \"Negatif Yorum\",\n",
      "    \"6\": \"Vade\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Destek\": 1,\n",
      "    \"Diren\\u00e7\": 2,\n",
      "    \"Hedef\": 3,\n",
      "    \"Negatif Yorum\": 5,\n",
      "    \"O\": 0,\n",
      "    \"Pozitif Yorum\": 4,\n",
      "    \"Vade\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128000\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/dbmdz/bert-base-turkish-128k-uncased/resolve/main/pytorch_model.bin from cache at /Users/damlakonur/.cache/huggingface/transformers/3345ec0d05fa890a371a29d54e90dfe6135aa8a16486d037cd5bd1c3665b5614.1568b123824a920fb754ca0cdf98bdaa3254b5cba00f451e08bd7a963a879fff\n",
      "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_path,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner-bist30\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/engibeer/bert-finetuned-ner-bist30 into local empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 909\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 342\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 113\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Direnç seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Hedef seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Destek seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Vade seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "                                                 \n",
      "\u001b[A                                            \n",
      "\n",
      "\u001b[A\u001b[A                                           \n",
      "\n",
      "\n",
      " 33%|███▎      | 114/342 [33:34<22:08,  5.82s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[ASaving model checkpoint to bert-finetuned-ner-bist30/checkpoint-114\n",
      "Configuration saved in bert-finetuned-ner-bist30/checkpoint-114/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4680156111717224, 'eval_precision': 0.2644444444444444, 'eval_recall': 0.3742138364779874, 'eval_f1': 0.3098958333333333, 'eval_accuracy': 0.8279985283296541, 'eval_runtime': 23.2376, 'eval_samples_per_second': 4.863, 'eval_steps_per_second': 0.646, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner-bist30/checkpoint-114/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner-bist30/checkpoint-114/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner-bist30/checkpoint-114/special_tokens_map.json\n",
      "tokenizer config file saved in bert-finetuned-ner-bist30/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner-bist30/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 113\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Direnç seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Hedef seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Destek seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Vade seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "                                                 \n",
      "\u001b[A                                            \n",
      "\n",
      "\u001b[A\u001b[A                                           \n",
      "\n",
      "\n",
      " 33%|███▎      | 114/342 [47:05<22:08,  5.82s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[ASaving model checkpoint to bert-finetuned-ner-bist30/checkpoint-228\n",
      "Configuration saved in bert-finetuned-ner-bist30/checkpoint-228/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.42785879969596863, 'eval_precision': 0.2980132450331126, 'eval_recall': 0.42452830188679247, 'eval_f1': 0.35019455252918297, 'eval_accuracy': 0.8360927152317881, 'eval_runtime': 23.1994, 'eval_samples_per_second': 4.871, 'eval_steps_per_second': 0.647, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner-bist30/checkpoint-228/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner-bist30/checkpoint-228/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner-bist30/checkpoint-228/special_tokens_map.json\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A***** Running Evaluation *****\n",
      "  Num examples = 113\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Direnç seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Hedef seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Destek seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Vade seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "                                                 \n",
      "\u001b[A                                            \n",
      "\n",
      "\u001b[A\u001b[A                                           \n",
      "\n",
      "\n",
      " 33%|███▎      | 114/342 [1:00:11<22:08,  5.82s/it]\n",
      "\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[ASaving model checkpoint to bert-finetuned-ner-bist30/checkpoint-342\n",
      "Configuration saved in bert-finetuned-ner-bist30/checkpoint-342/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4142546057701111, 'eval_precision': 0.31788079470198677, 'eval_recall': 0.4528301886792453, 'eval_f1': 0.3735408560311284, 'eval_accuracy': 0.8473142016188374, 'eval_runtime': 23.3399, 'eval_samples_per_second': 4.841, 'eval_steps_per_second': 0.643, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner-bist30/checkpoint-342/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner-bist30/checkpoint-342/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner-bist30/checkpoint-342/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "                                                   \n",
      "\u001b[A                                            \n",
      "\n",
      " 33%|███▎      | 114/342 [1:00:20<22:08,  5.82s/it]\n",
      "100%|██████████| 342/342 [39:37<00:00,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2377.767, 'train_samples_per_second': 1.147, 'train_steps_per_second': 0.144, 'train_loss': 0.34235761318987573, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=342, training_loss=0.34235761318987573, metrics={'train_runtime': 2377.767, 'train_samples_per_second': 1.147, 'train_steps_per_second': 0.144, 'train_loss': 0.34235761318987573, 'epoch': 3.0})"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 113\n",
      "  Batch size = 8\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Direnç seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Hedef seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Destek seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Vade seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "100%|██████████| 15/15 [00:21<00:00,  1.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.4142546057701111,\n",
       " 'eval_precision': 0.31788079470198677,\n",
       " 'eval_recall': 0.4528301886792453,\n",
       " 'eval_f1': 0.3735408560311284,\n",
       " 'eval_accuracy': 0.8473142016188374,\n",
       " 'eval_runtime': 23.4775,\n",
       " 'eval_samples_per_second': 4.813,\n",
       " 'eval_steps_per_second': 0.639,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in model-ner/bert-finetuned-ner-bist30/config.json\n",
      "Model weights saved in model-ner/bert-finetuned-ner-bist30/pytorch_model.bin\n",
      "tokenizer config file saved in model-ner/tokenizer/tokenizer_config.json\n",
      "Special tokens file saved in model-ner/tokenizer/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('model-ner/tokenizer/tokenizer_config.json',\n",
       " 'model-ner/tokenizer/special_tokens_map.json',\n",
       " 'model-ner/tokenizer/vocab.txt',\n",
       " 'model-ner/tokenizer/added_tokens.json',\n",
       " 'model-ner/tokenizer/tokenizer.json')"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"model-ner/bert-finetuned-ner-bist30\")\n",
    "tokenizer.save_pretrained(\"model-ner/tokenizer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model-ner/bert-finetuned-ner-bist30/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"model-ner/bert-finetuned-ner-bist30\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"Destek\",\n",
      "    \"2\": \"Diren\\u00e7\",\n",
      "    \"3\": \"Hedef\",\n",
      "    \"4\": \"Pozitif Yorum\",\n",
      "    \"5\": \"Negatif Yorum\",\n",
      "    \"6\": \"Vade\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Destek\": 1,\n",
      "    \"Diren\\u00e7\": 2,\n",
      "    \"Hedef\": 3,\n",
      "    \"Negatif Yorum\": 5,\n",
      "    \"O\": 0,\n",
      "    \"Pozitif Yorum\": 4,\n",
      "    \"Vade\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128000\n",
      "}\n",
      "\n",
      "loading weights file model-ner/bert-finetuned-ner-bist30/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at model-ner/bert-finetuned-ner-bist30.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity': 'Destek', 'score': 0.88141555, 'index': 6, 'word': '4', 'start': 18, 'end': 19}, {'entity': 'Destek', 'score': 0.8917565, 'index': 7, 'word': ',', 'start': 19, 'end': 20}, {'entity': 'Destek', 'score': 0.8938298, 'index': 8, 'word': '45', 'start': 20, 'end': 22}, {'entity': 'Direnç', 'score': 0.988557, 'index': 11, 'word': '4', 'start': 32, 'end': 33}, {'entity': 'Direnç', 'score': 0.98773205, 'index': 12, 'word': ',', 'start': 33, 'end': 34}, {'entity': 'Direnç', 'score': 0.9822239, 'index': 13, 'word': '85', 'start': 34, 'end': 36}]\n"
     ]
    }
   ],
   "source": [
    "pre_model = AutoModelForTokenClassification.from_pretrained(\"model-ner/bert-finetuned-ner-bist30\")\n",
    "nlp = pipeline(\"ner\", model=pre_model, tokenizer=tokenizer)\n",
    "ex = \"#ykbnk \\n\\nDestek : 4,45\\nDirenç  :4,85\"\n",
    "ner_results = nlp(ex)\n",
    "print(ner_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model-ner/bert-finetuned-ner-bist30/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"model-ner/bert-finetuned-ner-bist30\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"Destek\",\n",
      "    \"2\": \"Diren\\u00e7\",\n",
      "    \"3\": \"Hedef\",\n",
      "    \"4\": \"Pozitif Yorum\",\n",
      "    \"5\": \"Negatif Yorum\",\n",
      "    \"6\": \"Vade\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Destek\": 1,\n",
      "    \"Diren\\u00e7\": 2,\n",
      "    \"Hedef\": 3,\n",
      "    \"Negatif Yorum\": 5,\n",
      "    \"O\": 0,\n",
      "    \"Pozitif Yorum\": 4,\n",
      "    \"Vade\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128000\n",
      "}\n",
      "\n",
      "loading configuration file model-ner/bert-finetuned-ner-bist30/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"model-ner/bert-finetuned-ner-bist30\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"Destek\",\n",
      "    \"2\": \"Diren\\u00e7\",\n",
      "    \"3\": \"Hedef\",\n",
      "    \"4\": \"Pozitif Yorum\",\n",
      "    \"5\": \"Negatif Yorum\",\n",
      "    \"6\": \"Vade\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Destek\": 1,\n",
      "    \"Diren\\u00e7\": 2,\n",
      "    \"Hedef\": 3,\n",
      "    \"Negatif Yorum\": 5,\n",
      "    \"O\": 0,\n",
      "    \"Pozitif Yorum\": 4,\n",
      "    \"Vade\": 6\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128000\n",
      "}\n",
      "\n",
      "loading weights file model-ner/bert-finetuned-ner-bist30/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at model-ner/bert-finetuned-ner-bist30.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "Didn't find file model-ner/bert-finetuned-ner-bist30/added_tokens.json. We won't load it.\n",
      "loading file model-ner/bert-finetuned-ner-bist30/vocab.txt\n",
      "loading file model-ner/bert-finetuned-ner-bist30/tokenizer.json\n",
      "loading file None\n",
      "loading file model-ner/bert-finetuned-ner-bist30/special_tokens_map.json\n",
      "loading file model-ner/bert-finetuned-ner-bist30/tokenizer_config.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'Destek',\n",
       "  'score': 0.8890006,\n",
       "  'word': '4, 45',\n",
       "  'start': 18,\n",
       "  'end': 22},\n",
       " {'entity_group': 'Direnç',\n",
       "  'score': 0.986171,\n",
       "  'word': '4, 85',\n",
       "  'start': 32,\n",
       "  'end': 36}]"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=\"model-ner/bert-finetuned-ner-bist30\", aggregation_strategy=\"simple\"\n",
    ")\n",
    "token_classifier(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[18, 22, 'Destek'], [32, 36, 'Direnç']]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[7, 12, 'Destek'],\n",
       " [20, 25, 'Direnç'],\n",
       " [26, 31, 'Direnç'],\n",
       " [51, 55, 'Destek'],\n",
       " [63, 67, 'Direnç'],\n",
       " [82, 86, 'Destek'],\n",
       " [94, 98, 'Direnç'],\n",
       " [118, 122, 'Destek'],\n",
       " [130, 134, 'Direnç'],\n",
       " [135, 139, 'Direnç'],\n",
       " [140, 144, 'Direnç'],\n",
       " [164, 168, 'Destek'],\n",
       " [176, 180, 'Direnç'],\n",
       " [181, 185, 'Direnç']]"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[50].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'Hedef',\n",
       "  'score': 0.8887491,\n",
       "  'word': '3. 70 \\\\ / 3. 76',\n",
       "  'start': 194,\n",
       "  'end': 205},\n",
       " {'entity_group': 'Vade',\n",
       "  'score': 0.61369735,\n",
       "  'word': 'kısa',\n",
       "  'start': 219,\n",
       "  'end': 223},\n",
       " {'entity_group': 'Pozitif Yorum',\n",
       "  'score': 0.7384516,\n",
       "  'word': 'da toparlanma var devam ✅',\n",
       "  'start': 224,\n",
       "  'end': 249}]"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_classifier(\"#xulou\\n\\n#ykbnk 3.46 kapanış ✅\\n\\nBankalara örnek olarak yapikredi bakalım🎈\\n\\n3.45 pivot 🎯 üzerinde devam ederse sorun yok şimdilik...\\n\\n3.53 yukarıda ki ilk kritik rakam \\n\\n2.30 dan harekete başladı 3.70\\/ 3.76 hedefleri 🎯\\n\\nKısa da toparlanma var devam ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 114\n",
      "  Batch size = 8\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Hedef seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Vade seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Direnç seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Destek seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    }
   ],
   "source": [
    "preds_output = trainer.predict(test_dataset)\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.40804818272590637,\n",
       " 'test_precision': 0.46153846153846156,\n",
       " 'test_recall': 0.5675675675675675,\n",
       " 'test_f1': 0.509090909090909,\n",
       " 'test_accuracy': 0.8589930682232761,\n",
       " 'test_runtime': 26.1912,\n",
       " 'test_samples_per_second': 4.353,\n",
       " 'test_steps_per_second': 0.573}"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_output = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       ...,\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,    0, ..., -100, -100, -100],\n",
       "       [-100,    0,    0, ..., -100, -100, -100]])"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_output.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_predictions(predictions, label_ids): \n",
    "    preds = np.argmax(predictions, axis=2) \n",
    "    batch_size, seq_len = preds.shape \n",
    "    labels_list, preds_list = [], []\n",
    "    for batch_idx in range(batch_size): \n",
    "        example_labels, example_preds = [], [] \n",
    "        for seq_idx in range(seq_len):\n",
    "                    # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100: \n",
    "                example_labels.append(id2label[label_ids[batch_idx][seq_idx]]) \n",
    "                example_preds.append(id2label[preds[batch_idx][seq_idx]])\n",
    "                labels_list.append(example_labels)\n",
    "                preds_list.append(example_preds)\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prd, y_tr = align_predictions(preds_output.predictions,preds_output.label_ids) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Hedef seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Vade seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Direnç seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Destek seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ade       0.47      0.30      0.37      1880\n",
      "        edef       0.13      0.17      0.15      2063\n",
      "egatif Yorum       0.11      0.16      0.13       705\n",
      "       estek       0.84      0.81      0.83      7529\n",
      "       irenç       0.73      0.87      0.79      7561\n",
      "ozitif Yorum       0.09      0.18      0.12      3007\n",
      "\n",
      "   micro avg       0.52      0.63      0.57     22745\n",
      "   macro avg       0.40      0.41      0.40     22745\n",
      "weighted avg       0.59      0.63      0.60     22745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "print(classification_report(y_tr, y_prd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = token_classifier(\"#xulou\\n\\n#ykbnk 3.46 kapanış ✅\\n\\nBankalara örnek olarak yapikredi bakalım🎈\\n\\n3.45 pivot 🎯 üzerinde devam ederse sorun yok şimdilik...\\n\\n3.53 yukarıda ki ilk kritik rakam \\n\\n2.30 dan harekete başladı 3.70\\/ 3.76 hedefleri 🎯\\n\\nKısa da toparlanma var devam ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 9989 (\\N{WHITE HEAVY CHECK MARK}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/usr/local/lib/python3.9/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 127880 (\\N{BALLOON}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/usr/local/lib/python3.9/site-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 127919 (\\N{DIRECT HIT}) missing from current font.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "custom_tweet = \"#xulou\\n\\n#ykbnk 3.46 kapanış ✅\\n\\nBankalara örnek olarak yapikredi bakalım🎈\\n\\n3.45 pivot 🎯 üzerinde devam ederse sorun yok şimdilik...\\n\\n3.53 yukarıda ki ilk kritik rakam \\n\\n2.30 dan harekete başladı 3.70\\/ 3.76 hedefleri 🎯\\n\\nKısa da toparlanma var devam ✅\"\n",
    "preds_df = pd.DataFrame(prediction)\n",
    "plt.bar(preds_df[\"entity_group\"], 100 * preds_df[\"score\"], color='C0')\n",
    "plt.title(f'\"{custom_tweet}\"')\n",
    "plt.ylabel(\"Class probability (%)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
