{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token Classification for Pozitif Yorum - Negatif Yorum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json('Data/neg-pos-yorum.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "664"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Path and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"dbmdz/bert-base-turkish-128k-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_path, max_len=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTokenizedLabels(data):\n",
    "    labels_list = []\n",
    "    for text, doccano_label_list in zip(data['text'], data['label']):\n",
    "        encoding = tokenizer(text, return_offsets_mapping=True)\n",
    "        labels = [None] * len(encoding[\"offset_mapping\"])\n",
    "        doccano_label_index = 0\n",
    "        for index, token_tupple in enumerate(encoding[\"offset_mapping\"]):\n",
    "            \n",
    "            doccano_label = doccano_label_list[doccano_label_index]\n",
    "            if(token_tupple == (0,0)): continue\n",
    "\n",
    "            if(token_tupple[0] > doccano_label[1] and ((doccano_label_index+1) != len(doccano_label_list))):\n",
    "                doccano_label_index += 1\n",
    "                doccano_label = doccano_label_list[doccano_label_index]\n",
    "\n",
    "            if(doccano_label[0] <= token_tupple[0] <= doccano_label[1]):\n",
    "                labels[index] = doccano_label[2]\n",
    "            else:\n",
    "                labels[index] = 'O'\n",
    "        labels_list.append(labels)\n",
    "    return pd.Series(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enumLabels(bert_labels):\n",
    "    label2id = {None:-100, 'O':0, 'Pozitif Yorum':1, 'Negatif Yorum':2}\n",
    "    id2label = {v:k for k,v in label2id.items()}\n",
    "    bert_labels_id = bert_labels.map(lambda x: [label2id[y] for y in x])\n",
    "    return bert_labels_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_labels = getTokenizedLabels(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_labels_id = enumLabels(bert_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokens'] = data.text.apply(lambda x: tokenizer(x).tokens())\n",
    "data['input_ids'] = data.text.apply(lambda x: tokenizer(x).input_ids)\n",
    "data['attention_mask'] = data.text.apply(lambda x: tokenizer(x).attention_mask)\n",
    "data['token_type_ids'] = data.text.apply(lambda x: tokenizer(x).token_type_ids)\n",
    "data['bert_labels']= bert_labels\n",
    "data['bert_label_ids'] = bert_labels_id\n",
    "df = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>token_type_ids</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2, 7, 62873, 98360, 23, 18, 5244, 7, 2158, 18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[2, 7, 62873, 98360, 74996, 1017, 24, 16, 1056...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2, 7904, 80300, 17468, 16, 22, 18, 84248, 11,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[2, 9725, 11487, 17468, 47268, 1045, 43459, 10...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[2, 7, 2158, 18551, 1013, 28, 18, 8410, 29, 18...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [2, 7, 62873, 98360, 23, 18, 5244, 7, 2158, 18...   \n",
       "1  [2, 7, 62873, 98360, 74996, 1017, 24, 16, 1056...   \n",
       "2  [2, 7904, 80300, 17468, 16, 22, 18, 84248, 11,...   \n",
       "3  [2, 9725, 11487, 17468, 47268, 1045, 43459, 10...   \n",
       "4  [2, 7, 2158, 18551, 1013, 28, 18, 8410, 29, 18...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...   \n",
       "\n",
       "                                      token_type_ids  \\\n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                              labels  \n",
       "0  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "1  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "3  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4  [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(['id', 'label', 'text', 'date', 'user', 'rt', 'fav', 'followers', 'verified', 'tokens', 'bert_labels'], axis=1, inplace=True)\n",
    "data.rename(columns={'bert_label_ids':'labels'}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(531, 66, 67)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, random_state=42)\n",
    "train, val = train_test_split(train, test_size=0.11, random_state=42)\n",
    "len(train), len(val), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(drop=True, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "train_dataset = datasets.Dataset.from_pandas(train)\n",
    "test_dataset = datasets.Dataset.from_pandas(test)\n",
    "val_dataset = datasets.Dataset.from_pandas(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'token_type_ids', 'labels'],\n",
       "    num_rows: 531\n",
       "})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = [\"O\", \" Pozitif Yorum\", \" Negatif Yorum\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        'Pozitif_Yorum' : all_metrics['Pozitif Yorum'],\n",
    "        'Negatif_Yorum' : all_metrics['Negatif Yorum'],\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2id = {' O':0, ' Pozitif Yorum':1, ' Negatif Yorum':2}\n",
    "id2label = {v:k for k,v in label2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-turkish-128k-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-turkish-128k-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_path,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    \"bert-finetuned-ner2-bist30\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 531\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 67/335 [07:17<23:24,  5.24s/it]***** Running Evaluation *****\n",
      "  Num examples = 67\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0546875, 'recall': 0.10294117647058823, 'f1': 0.07142857142857142, 'number': 68}\" of type <class 'dict'> for key \"eval/Pozitif_Yorum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 8}\" of type <class 'dict'> for key \"eval/Negatif_Yorum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                \n",
      " 20%|██        | 67/335 [07:33<23:24,  5.24s/it]Saving model checkpoint to bert-finetuned-ner2-bist30/checkpoint-67\n",
      "Configuration saved in bert-finetuned-ner2-bist30/checkpoint-67/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3910437524318695, 'eval_Pozitif_Yorum': {'precision': 0.0546875, 'recall': 0.10294117647058823, 'f1': 0.07142857142857142, 'number': 68}, 'eval_Negatif_Yorum': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 8}, 'eval_precision': 0.05384615384615385, 'eval_recall': 0.09210526315789473, 'eval_f1': 0.0679611650485437, 'eval_accuracy': 0.8520078629598428, 'eval_runtime': 15.6516, 'eval_samples_per_second': 4.281, 'eval_steps_per_second': 0.575, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner2-bist30/checkpoint-67/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner2-bist30/checkpoint-67/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner2-bist30/checkpoint-67/special_tokens_map.json\n",
      " 40%|████      | 134/335 [14:52<18:03,  5.39s/it] ***** Running Evaluation *****\n",
      "  Num examples = 67\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.10833333333333334, 'recall': 0.19117647058823528, 'f1': 0.13829787234042554, 'number': 68}\" of type <class 'dict'> for key \"eval/Pozitif_Yorum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.15384615384615385, 'recall': 0.25, 'f1': 0.1904761904761905, 'number': 8}\" of type <class 'dict'> for key \"eval/Negatif_Yorum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                 \n",
      " 40%|████      | 134/335 [15:08<18:03,  5.39s/it]Saving model checkpoint to bert-finetuned-ner2-bist30/checkpoint-134\n",
      "Configuration saved in bert-finetuned-ner2-bist30/checkpoint-134/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3016418218612671, 'eval_Pozitif_Yorum': {'precision': 0.10833333333333334, 'recall': 0.19117647058823528, 'f1': 0.13829787234042554, 'number': 68}, 'eval_Negatif_Yorum': {'precision': 0.15384615384615385, 'recall': 0.25, 'f1': 0.1904761904761905, 'number': 8}, 'eval_precision': 0.11278195488721804, 'eval_recall': 0.19736842105263158, 'eval_f1': 0.14354066985645933, 'eval_accuracy': 0.883459702330806, 'eval_runtime': 15.5614, 'eval_samples_per_second': 4.306, 'eval_steps_per_second': 0.578, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner2-bist30/checkpoint-134/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner2-bist30/checkpoint-134/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner2-bist30/checkpoint-134/special_tokens_map.json\n",
      " 60%|██████    | 201/335 [22:27<11:13,  5.03s/it]***** Running Evaluation *****\n",
      "  Num examples = 67\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.14563106796116504, 'recall': 0.22058823529411764, 'f1': 0.17543859649122806, 'number': 68}\" of type <class 'dict'> for key \"eval/Pozitif_Yorum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16666666666666666, 'recall': 0.375, 'f1': 0.23076923076923078, 'number': 8}\" of type <class 'dict'> for key \"eval/Negatif_Yorum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                 \n",
      " 60%|██████    | 201/335 [22:42<11:13,  5.03s/it]Saving model checkpoint to bert-finetuned-ner2-bist30/checkpoint-201\n",
      "Configuration saved in bert-finetuned-ner2-bist30/checkpoint-201/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2868387699127197, 'eval_Pozitif_Yorum': {'precision': 0.14563106796116504, 'recall': 0.22058823529411764, 'f1': 0.17543859649122806, 'number': 68}, 'eval_Negatif_Yorum': {'precision': 0.16666666666666666, 'recall': 0.375, 'f1': 0.23076923076923078, 'number': 8}, 'eval_precision': 0.1487603305785124, 'eval_recall': 0.23684210526315788, 'eval_f1': 0.182741116751269, 'eval_accuracy': 0.8994664420106712, 'eval_runtime': 15.5823, 'eval_samples_per_second': 4.3, 'eval_steps_per_second': 0.578, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner2-bist30/checkpoint-201/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner2-bist30/checkpoint-201/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner2-bist30/checkpoint-201/special_tokens_map.json\n",
      " 80%|████████  | 268/335 [30:19<06:49,  6.11s/it]***** Running Evaluation *****\n",
      "  Num examples = 67\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.1702127659574468, 'recall': 0.23529411764705882, 'f1': 0.19753086419753088, 'number': 68}\" of type <class 'dict'> for key \"eval/Pozitif_Yorum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.17647058823529413, 'recall': 0.375, 'f1': 0.24, 'number': 8}\" of type <class 'dict'> for key \"eval/Negatif_Yorum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                 \n",
      " 80%|████████  | 268/335 [30:36<06:49,  6.11s/it]Saving model checkpoint to bert-finetuned-ner2-bist30/checkpoint-268\n",
      "Configuration saved in bert-finetuned-ner2-bist30/checkpoint-268/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30167296528816223, 'eval_Pozitif_Yorum': {'precision': 0.1702127659574468, 'recall': 0.23529411764705882, 'f1': 0.19753086419753088, 'number': 68}, 'eval_Negatif_Yorum': {'precision': 0.17647058823529413, 'recall': 0.375, 'f1': 0.24, 'number': 8}, 'eval_precision': 0.17117117117117117, 'eval_recall': 0.25, 'eval_f1': 0.2032085561497326, 'eval_accuracy': 0.8944116821117664, 'eval_runtime': 16.4405, 'eval_samples_per_second': 4.075, 'eval_steps_per_second': 0.547, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner2-bist30/checkpoint-268/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner2-bist30/checkpoint-268/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner2-bist30/checkpoint-268/special_tokens_map.json\n",
      "100%|██████████| 335/335 [38:18<00:00,  5.27s/it]***** Running Evaluation *****\n",
      "  Num examples = 67\n",
      "  Batch size = 8\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Trainer is attempting to log a value of \"{'precision': 0.2, 'recall': 0.27941176470588236, 'f1': 0.23312883435582823, 'number': 68}\" of type <class 'dict'> for key \"eval/Pozitif_Yorum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "Trainer is attempting to log a value of \"{'precision': 0.16666666666666666, 'recall': 0.375, 'f1': 0.23076923076923078, 'number': 8}\" of type <class 'dict'> for key \"eval/Negatif_Yorum\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "                                                 \n",
      "100%|██████████| 335/335 [38:34<00:00,  5.27s/it]Saving model checkpoint to bert-finetuned-ner2-bist30/checkpoint-335\n",
      "Configuration saved in bert-finetuned-ner2-bist30/checkpoint-335/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3065752387046814, 'eval_Pozitif_Yorum': {'precision': 0.2, 'recall': 0.27941176470588236, 'f1': 0.23312883435582823, 'number': 68}, 'eval_Negatif_Yorum': {'precision': 0.16666666666666666, 'recall': 0.375, 'f1': 0.23076923076923078, 'number': 8}, 'eval_precision': 0.19469026548672566, 'eval_recall': 0.2894736842105263, 'eval_f1': 0.23280423280423282, 'eval_accuracy': 0.8946925021061499, 'eval_runtime': 15.8911, 'eval_samples_per_second': 4.216, 'eval_steps_per_second': 0.566, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in bert-finetuned-ner2-bist30/checkpoint-335/pytorch_model.bin\n",
      "tokenizer config file saved in bert-finetuned-ner2-bist30/checkpoint-335/tokenizer_config.json\n",
      "Special tokens file saved in bert-finetuned-ner2-bist30/checkpoint-335/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "100%|██████████| 335/335 [38:47<00:00,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 2327.5608, 'train_samples_per_second': 1.141, 'train_steps_per_second': 0.144, 'train_loss': 0.29856952268685866, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=335, training_loss=0.29856952268685866, metrics={'train_runtime': 2327.5608, 'train_samples_per_second': 1.141, 'train_steps_per_second': 0.144, 'train_loss': 0.29856952268685866, 'epoch': 5.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in model/bert-finetuned-ner2-bist30/config.json\n",
      "Model weights saved in model/bert-finetuned-ner2-bist30/pytorch_model.bin\n",
      "tokenizer config file saved in model/tokenizer2/tokenizer_config.json\n",
      "Special tokens file saved in model/tokenizer2/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('model/tokenizer2/tokenizer_config.json',\n",
       " 'model/tokenizer2/special_tokens_map.json',\n",
       " 'model/tokenizer2/vocab.txt',\n",
       " 'model/tokenizer2/added_tokens.json',\n",
       " 'model/tokenizer2/tokenizer.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"model/bert-finetuned-ner2-bist30\")\n",
    "tokenizer.save_pretrained(\"model/tokenizer2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file model/bert-finetuned-ner2-bist30/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"model/bert-finetuned-ner2-bist30\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \" O\",\n",
      "    \"1\": \" Pozitif Yorum\",\n",
      "    \"2\": \" Negatif Yorum\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \" Negatif Yorum\": 2,\n",
      "    \" O\": 0,\n",
      "    \" Pozitif Yorum\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128000\n",
      "}\n",
      "\n",
      "loading configuration file model/bert-finetuned-ner2-bist30/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"model/bert-finetuned-ner2-bist30\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \" O\",\n",
      "    \"1\": \" Pozitif Yorum\",\n",
      "    \"2\": \" Negatif Yorum\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \" Negatif Yorum\": 2,\n",
      "    \" O\": 0,\n",
      "    \" Pozitif Yorum\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.20.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128000\n",
      "}\n",
      "\n",
      "loading weights file model/bert-finetuned-ner2-bist30/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at model/bert-finetuned-ner2-bist30.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n",
      "Didn't find file model/tokenizer2/added_tokens.json. We won't load it.\n",
      "loading file model/tokenizer2/vocab.txt\n",
      "loading file model/tokenizer2/tokenizer.json\n",
      "loading file None\n",
      "loading file model/tokenizer2/special_tokens_map.json\n",
      "loading file model/tokenizer2/tokenizer_config.json\n"
     ]
    }
   ],
   "source": [
    "token_classifier = pipeline(\n",
    "    \"token-classification\", model=\"model/bert-finetuned-ner2-bist30\", aggregation_strategy=\"simple\", tokenizer=\"model/tokenizer2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': ' O',\n",
       "  'score': 0.8734143,\n",
       "  'word': '# asels',\n",
       "  'start': 0,\n",
       "  'end': 6},\n",
       " {'entity_group': ' Negatif Yorum',\n",
       "  'score': 0.4932291,\n",
       "  'word': 'geri ceki',\n",
       "  'start': 7,\n",
       "  'end': 16},\n",
       " {'entity_group': ' Pozitif Yorum',\n",
       "  'score': 0.6130686,\n",
       "  'word': '##lme bekliyorum!',\n",
       "  'start': 16,\n",
       "  'end': 32}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex=\"#ASELS geri çekilme bekliyorum !\"\n",
    "token_classifier(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 67\n",
      "  Batch size = 8\n",
      "100%|██████████| 9/9 [00:14<00:00,  1.47s/it]/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Pozitif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  Negatif Yorum seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    }
   ],
   "source": [
    "preds_output = trainer.predict(test_dataset)\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_predictions(predictions, label_ids): \n",
    "    preds = np.argmax(predictions, axis=2) \n",
    "    batch_size, seq_len = preds.shape \n",
    "    labels_list, preds_list = [], []\n",
    "    for batch_idx in range(batch_size): \n",
    "        example_labels, example_preds = [], [] \n",
    "        for seq_idx in range(seq_len):\n",
    "                    # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100: \n",
    "                example_labels.append(id2label[label_ids[batch_idx][seq_idx]]) \n",
    "                example_preds.append(id2label[preds[batch_idx][seq_idx]])\n",
    "                labels_list.append(example_labels)\n",
    "                preds_list.append(example_preds)\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prd, y_tr = align_predictions(preds_output.predictions,preds_output.label_ids) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning:  O seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Negatif Yorum       0.20      0.36      0.26       527\n",
      "            O       0.39      0.49      0.44      6452\n",
      "Pozitif Yorum       0.19      0.25      0.21      3628\n",
      "\n",
      "    micro avg       0.31      0.40      0.35     10607\n",
      "    macro avg       0.26      0.37      0.30     10607\n",
      " weighted avg       0.31      0.40      0.35     10607\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "print(classification_report(y_tr, y_prd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
